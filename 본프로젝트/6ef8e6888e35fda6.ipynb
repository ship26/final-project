{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49caf83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: schedule in c:\\users\\infin\\anaconda3\\lib\\site-packages (1.1.0)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0281c27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import schedule\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d33283d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawling_yester_day():\n",
    "    \n",
    "    yesterday = now - timedelta(1)\n",
    "    yesterday.year,yesterday.month, yesterday.day\n",
    "    format = '%Y-%m-%d'\n",
    "    str_yesterday = datetime.datetime.strftime(yesterday,format)\n",
    "    yesterday_yymmdd = str_yesterday.split('-')\n",
    "    yesterday_yymmdd = [int (i) for i in yesterday_yymmdd]\n",
    "  \n",
    "    \n",
    "    press_list = {'한국경제':'015', '매일경제':'009', '조선일보':'023', '동아일보':'020', '한겨레신문':'028', '경향신문':'032'}\n",
    "\n",
    "    press_names = list(press_list.keys())\n",
    "    press_codes = list(press_list.values())\n",
    "\n",
    "# 크롤링 할 대상 입력\n",
    "\n",
    "    year = yesterday_yymmdd[0]\n",
    "\n",
    "    for press in press_names:\n",
    "    \n",
    "        to_crawl_press_this_time = press\n",
    "        presscode = press_list[to_crawl_press_this_time]\n",
    "\n",
    "# 6개 신문사 불러오기 \n",
    "\n",
    "        month = yesterday_yymmdd[1]\n",
    "        day = yesterday_yymmdd[2]\n",
    "\n",
    "        df = pd.DataFrame(columns=[\"press\",\"title\",\"date\"])\n",
    "        yesterday_data = []\n",
    "    \n",
    "        if month < 10:\n",
    "            month = f\"0{month}\"\n",
    "        print(f'{to_crawl_press_this_time}의 {month}월 {day}일 기사를 크롤링합니다.')\n",
    "        print(\"**************************************\")\n",
    "\n",
    "        if day in tqdm(range(1,32)):\n",
    "\n",
    "\n",
    "            # URL에 접속 시도\n",
    "\n",
    "            # 1 ~ 9일에 대한 URL 접근\n",
    "                if day < 10:\n",
    "                    URL = f'https://media.naver.com/press/{presscode}/newspaper?date={year}{month}0{day}'\n",
    "                    print(URL)\n",
    "                    response = requests.get(URL)\n",
    "                    print(response)\n",
    "            # 10일부터에 대한 URL 접근\n",
    "                else:\n",
    "                    URL = f'https://media.naver.com/press/{presscode}/newspaper?date={year}{month}{day}'\n",
    "                    print(URL)\n",
    "                    response = requests.get(URL)\n",
    "                    print(response)\n",
    "                time.sleep(1)\n",
    "            # html 파싱 시작\n",
    "                soup = BeautifulSoup(response.text)\n",
    "                page = soup.select('div.newspaper_inner')\n",
    "\n",
    "            # 혹시나 1면도 없으면 신문 없는 날\n",
    "                if len(page) < 1:\n",
    "                    print(f'{day}일자는 기사가 없습니다 데헷')\n",
    "                    print('-' * 25)\n",
    "                    continue\n",
    "\n",
    "            # 신문 지면 발견하면 크롤링\n",
    "                else:\n",
    "                    print(f'{day}일자 기사를 크롤링합니다.')\n",
    "                    print('-' * 25)\n",
    "\n",
    "                # 하루치 기사를 담을 리스트\n",
    "                    oneday_titles = []\n",
    "\n",
    "                # 지면별 헤드라인 탐색\n",
    "                    for _ in range(len(page)):\n",
    "                        page_titles = []\n",
    "                        title = soup.select('div.newspaper_inner')[_]\n",
    "                        titles = title.find_all('strong')\n",
    "\n",
    "                    # 헤드라인들 page_title 리스트에 담음\n",
    "                        for ttl in titles:\n",
    "                            news_title = ttl.text\n",
    "                        \n",
    "\n",
    "                            if day < 10:\n",
    "                                news = {'press':to_crawl_press_this_time,'title':news_title, 'date':f'{year}{month}0{day}'}\n",
    "\n",
    "                            else:\n",
    "                                news = {'press':to_crawl_press_this_time,'title':news_title, 'date':f'{year}{month}{day}'}\n",
    "\n",
    "\n",
    "                            yesterday_data.append(news)\n",
    "\n",
    "        df = df.append(yesterday_data)\n",
    "        df.to_csv(f'{to_crawl_press_this_time}_{year}_{month}_{day}.csv', encoding=\"UTF-8-sig\")\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2458779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawling_today_day():\n",
    "    \n",
    "    now =datetime.datetime.now()\n",
    "    now.year, now.month, now.day\n",
    "    format = '%Y-%m-%d'\n",
    "    str_now = datetime.datetime.strftime(now,format)\n",
    "    #오늘 날짜 가져오기\n",
    " \n",
    "    #어제 날짜 가져오기\n",
    "    now_yymmdd = str_now.split('-')\n",
    "    now_yymmdd = [int (i) for i in now_yymmdd]\n",
    "\n",
    "    \n",
    "    \n",
    "    press_list = {'한국경제':'015', '매일경제':'009', '조선일보':'023', '동아일보':'020', '한겨레신문':'028', '경향신문':'032'}\n",
    "    press_names = list(press_list.keys())\n",
    "    press_codes = list(press_list.values())    \n",
    "    \n",
    "# 크롤링 할 대상 입력\n",
    "\n",
    "    year = now_yymmdd[0]\n",
    "\n",
    "    for press in press_names:\n",
    "    \n",
    "        to_crawl_press_this_time = press\n",
    "        presscode = press_list[to_crawl_press_this_time]\n",
    "\n",
    "# 6개 신문사 불러오기 \n",
    "\n",
    "        month = now_yymmdd[1]\n",
    "        day = now_yymmdd[2]\n",
    "\n",
    "        df = pd.DataFrame(columns=[\"press\",\"title\",\"date\"])\n",
    "        today_data = []\n",
    "    \n",
    "        if month < 10:\n",
    "            month = f\"0{month}\"\n",
    "        print(f'{to_crawl_press_this_time}의 {month}월 {day}일 기사를 크롤링합니다.')\n",
    "        print(\"**************************************\")\n",
    "\n",
    "        if day in tqdm(range(1,32)):\n",
    "\n",
    "\n",
    "            # URL에 접속 시도\n",
    "\n",
    "            # 1 ~ 9일에 대한 URL 접근\n",
    "                if day < 10:\n",
    "                    URL = f'https://media.naver.com/press/{presscode}/newspaper?date={year}{month}0{day}'\n",
    "                    print(URL)\n",
    "                    response = requests.get(URL)\n",
    "                    print(response)\n",
    "            # 10일부터에 대한 URL 접근\n",
    "                else:\n",
    "                    URL = f'https://media.naver.com/press/{presscode}/newspaper?date={year}{month}{day}'\n",
    "                    print(URL)\n",
    "                    response = requests.get(URL)\n",
    "                    print(response)\n",
    "                time.sleep(1)\n",
    "            # html 파싱 시작\n",
    "                soup = BeautifulSoup(response.text)\n",
    "                page = soup.select('div.newspaper_inner')\n",
    "\n",
    "            # 혹시나 1면도 없으면 신문 없는 날\n",
    "                if len(page) < 1:\n",
    "                    print(f'{day}일자는 기사가 없습니다 데헷')\n",
    "                    print('-' * 25)\n",
    "                    continue\n",
    "\n",
    "            # 신문 지면 발견하면 크롤링\n",
    "                else:\n",
    "                    print(f'{day}일자 기사를 크롤링합니다.')\n",
    "                    print('-' * 25)\n",
    "\n",
    "                # 하루치 기사를 담을 리스트\n",
    "                    oneday_titles = []\n",
    "\n",
    "                # 지면별 헤드라인 탐색\n",
    "                    for _ in range(len(page)):\n",
    "                        page_titles = []\n",
    "                        title = soup.select('div.newspaper_inner')[_]\n",
    "                        titles = title.find_all('strong')\n",
    "\n",
    "                    # 헤드라인들 page_title 리스트에 담음\n",
    "                        for ttl in titles:\n",
    "                            news_title = ttl.text\n",
    "                        \n",
    "\n",
    "                            if day < 10:\n",
    "                                news = {'press':to_crawl_press_this_time,'title':news_title, 'date':f'{year}{month}0{day}'}\n",
    "\n",
    "                            else:\n",
    "                                news = {'press':to_crawl_press_this_time,'title':news_title, 'date':f'{year}{month}{day}'}\n",
    "\n",
    "\n",
    "                            today_data.append(news)\n",
    "\n",
    "        df = df.append(today_data)\n",
    "        df.to_csv(f'{to_crawl_press_this_time}_{year}_{month}_{day}.csv', encoding=\"UTF-8-sig\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "267cfec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge():\n",
    "    os.getcwd()# 파일들이 있는 폴더명으로 폴더내 파일 목록 확인\n",
    "    forders = os.listdir('C:\\\\Users\\\\infin\\\\Desktop\\\\python_p\\\\1s')\n",
    "    df_all = pd.DataFrame()\n",
    "    for i in range(1,len(forders)):\n",
    "        if forders[i].split('.')[1] == 'csv':\n",
    "            file = 'C:\\\\Users\\\\infin\\\\Desktop\\\\python_p\\\\1s/'+forders[i]\n",
    "            df= pd.read_csv(file,encoding='utf-8',index_col=0) \n",
    "            df_all = pd.concat([df_all, df])\n",
    "        \n",
    "    df_all.to_csv(f'{str_yesterday}_{str_now} merged file.csv', encoding=\"UTF-8-sig\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aba4e7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국경제의 07월 25일 기사를 크롤링합니다.\n",
      "**************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 24/31 [00:00<00:00, 60677.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://media.naver.com/press/015/newspaper?date=20220725\n",
      "<Response [200]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25일자 기사를 크롤링합니다.\n",
      "-------------------------\n",
      "매일경제의 07월 25일 기사를 크롤링합니다.\n",
      "**************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 24/31 [00:00<00:00, 25666.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://media.naver.com/press/009/newspaper?date=20220725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "25일자 기사를 크롤링합니다.\n",
      "-------------------------\n",
      "조선일보의 07월 25일 기사를 크롤링합니다.\n",
      "**************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 24/31 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://media.naver.com/press/023/newspaper?date=20220725\n",
      "<Response [200]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25일자 기사를 크롤링합니다.\n",
      "-------------------------\n",
      "동아일보의 07월 25일 기사를 크롤링합니다.\n",
      "**************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 24/31 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://media.naver.com/press/020/newspaper?date=20220725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "25일자 기사를 크롤링합니다.\n",
      "-------------------------\n",
      "한겨레신문의 07월 25일 기사를 크롤링합니다.\n",
      "**************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 24/31 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://media.naver.com/press/028/newspaper?date=20220725\n",
      "<Response [200]>\n",
      "25일자 기사를 크롤링합니다.\n",
      "-------------------------\n",
      "경향신문의 07월 25일 기사를 크롤링합니다.\n",
      "**************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 24/31 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://media.naver.com/press/032/newspaper?date=20220725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "25일자 기사를 크롤링합니다.\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "crawling_yester_day()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "388b5c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국경제의 07월 26일 기사를 크롤링합니다.\n",
      "**************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 25/31 [00:00<00:00, 50412.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://media.naver.com/press/015/newspaper?date=20220726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "26일자 기사를 크롤링합니다.\n",
      "-------------------------\n",
      "매일경제의 07월 26일 기사를 크롤링합니다.\n",
      "**************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 25/31 [00:00<00:00, 50388.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://media.naver.com/press/009/newspaper?date=20220726\n",
      "<Response [200]>\n",
      "26일자 기사를 크롤링합니다.\n",
      "-------------------------\n",
      "조선일보의 07월 26일 기사를 크롤링합니다.\n",
      "**************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 25/31 [00:00<00:00, 52219.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://media.naver.com/press/023/newspaper?date=20220726\n",
      "<Response [200]>\n",
      "26일자 기사를 크롤링합니다.\n",
      "-------------------------\n",
      "동아일보의 07월 26일 기사를 크롤링합니다.\n",
      "**************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 25/31 [00:00<00:00, 25091.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://media.naver.com/press/020/newspaper?date=20220726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "26일자 기사를 크롤링합니다.\n",
      "-------------------------\n",
      "한겨레신문의 07월 26일 기사를 크롤링합니다.\n",
      "**************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 25/31 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://media.naver.com/press/028/newspaper?date=20220726\n",
      "<Response [200]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26일자 기사를 크롤링합니다.\n",
      "-------------------------\n",
      "경향신문의 07월 26일 기사를 크롤링합니다.\n",
      "**************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 25/31 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://media.naver.com/press/032/newspaper?date=20220726\n",
      "<Response [200]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26일자 기사를 크롤링합니다.\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "crawling_today_day()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1a8f14fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0e9b06dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국경제의 07월 26일 기사를 크롤링합니다.\n",
      "**************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 25/31 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://media.naver.com/press/015/newspaper?date=20220726\n",
      "<Response [200]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26일자 기사를 크롤링합니다.\n",
      "-------------------------\n",
      "매일경제의 07월 26일 기사를 크롤링합니다.\n",
      "**************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 25/31 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://media.naver.com/press/009/newspaper?date=20220726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "26일자 기사를 크롤링합니다.\n",
      "-------------------------\n",
      "조선일보의 07월 26일 기사를 크롤링합니다.\n",
      "**************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 25/31 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://media.naver.com/press/023/newspaper?date=20220726\n",
      "<Response [200]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26일자 기사를 크롤링합니다.\n",
      "-------------------------\n",
      "동아일보의 07월 26일 기사를 크롤링합니다.\n",
      "**************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 25/31 [00:00<00:00, 22919.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://media.naver.com/press/020/newspaper?date=20220726\n",
      "<Response [200]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26일자 기사를 크롤링합니다.\n",
      "-------------------------\n",
      "한겨레신문의 07월 26일 기사를 크롤링합니다.\n",
      "**************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 25/31 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://media.naver.com/press/028/newspaper?date=20220726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "26일자 기사를 크롤링합니다.\n",
      "-------------------------\n",
      "경향신문의 07월 26일 기사를 크롤링합니다.\n",
      "**************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 25/31 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://media.naver.com/press/032/newspaper?date=20220726\n",
      "<Response [200]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26일자 기사를 크롤링합니다.\n",
      "-------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "the first argument must be callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7744/2217493494.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mschedule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"14:29\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrawling_today_day\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\schedule\\__init__.py\u001b[0m in \u001b[0;36mdo\u001b[1;34m(self, job_func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    623\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[1;32mreturn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0minvoked\u001b[0m \u001b[0mjob\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m         \"\"\"\n\u001b[1;32m--> 625\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjob_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m         \u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjob_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjob_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_schedule_next_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: the first argument must be callable"
     ]
    }
   ],
   "source": [
    "schedule.every().day.at(\"14:29\").do(crawling_today_day(),)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79ab68b",
   "metadata": {},
   "source": [
    "# step2.실행할 함수 선언\n",
    "def message():\n",
    "    print(\"스케쥴 실행중...\")\n",
    "\n",
    "# step3.실행 주기 설정\n",
    "schedule.every(1).seconds.do(message)\n",
    "\n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)\n",
    "\n",
    "    count = count + 1\n",
    "\n",
    "    if count > 5:\n",
    "        schedule.cancel_job(message)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
