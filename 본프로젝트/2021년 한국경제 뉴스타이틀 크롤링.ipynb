{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce9d02d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae85706",
   "metadata": {},
   "source": [
    "https://news.naver.com/newspaper/home?viewType=pc\n",
    "\n",
    "URL 양식\n",
    "https://media.naver.com/press/\n",
    "{언론사고유번호}/newspaper?date={날짜} \n",
    "\n",
    "한경 015\n",
    "매경 009\n",
    "조선 023\n",
    "동아 020\n",
    "한겨례 028\n",
    "경향 032\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535d4187",
   "metadata": {},
   "source": [
    "## 2021년  한국경제 타이틀크롤링 1월~12월 자동화 해보자! ㅍㅇㅌ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "674c9b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/12 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "('Connection aborted.', ConnectionResetError(10054, '현재 연결은 원격 호스트에 의해 강제로 끊겼습니다', None, 10054, None))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    444\u001b[0m                     \u001b[1;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m                     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    439\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1370\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1371\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1372\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1240\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1241\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1242\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1098\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1099\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1100\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] 현재 연결은 원격 호스트에 의해 강제로 끊겼습니다",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 resp = conn.urlopen(\n\u001b[0m\u001b[0;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 755\u001b[1;33m             retries = retries.increment(\n\u001b[0m\u001b[0;32m    756\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    531\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mread\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_method_retryable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mread\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    768\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 769\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    770\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    444\u001b[0m                     \u001b[1;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m                     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    439\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1370\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1371\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1372\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1240\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1241\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1242\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1098\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1099\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1100\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mProtocolError\u001b[0m: ('Connection aborted.', ConnectionResetError(10054, '현재 연결은 원격 호스트에 의해 강제로 끊겼습니다', None, 10054, None))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3252/983780248.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0m월_1\u001b[0m \u001b[1;33m<\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[0mdate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'2021010{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m월_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m                 response=requests.get('https://media.naver.com/press/015/newspaper',headers=request_headers,\n\u001b[0m\u001b[0;32m     15\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                 )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m     \"\"\"\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    540\u001b[0m         }\n\u001b[0;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mProtocolError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mMaxRetryError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionError\u001b[0m: ('Connection aborted.', ConnectionResetError(10054, '현재 연결은 원격 호스트에 의해 강제로 끊겼습니다', None, 10054, None))"
     ]
    }
   ],
   "source": [
    "for k in range(1,13):\n",
    "    globals()['df{}'.format(k)] = pd.DataFrame(columns=['press','title','date'])  #동적 변수 할당.\n",
    "columns=['press','title','date']\n",
    "\n",
    "request_headers = { 'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36' } \n",
    "for i in tqdm(range(1,13)):\n",
    "    time.sleep(2)\n",
    "    if i==1:\n",
    "        for 월_1 in range(1,31):\n",
    "            time.sleep(0.5)\n",
    "            하루타이틀=[]\n",
    "            if 월_1 <10:\n",
    "                date='2021010{}'.format(월_1)\n",
    "                response=requests.get('https://media.naver.com/press/015/newspaper',headers=request_headers,\n",
    "                params={'date':date}\n",
    "                )\n",
    "            else:\n",
    "                date='202101{}'.format(월_1)\n",
    "                response=requests.get('https://media.naver.com/press/015/newspaper',headers=request_headers,\n",
    "                params={'date':date}\n",
    "                )\n",
    "            \n",
    "            soup=BeautifulSoup(response.text)\n",
    "            면=soup.select('div.newspaper_inner')\n",
    "    \n",
    "            if len(면)<1:\n",
    "                print(f'{월_1}일자는 기사가 없습니다 데헷')\n",
    "                print('-'*25)\n",
    "                continue\n",
    "            else:\n",
    "                print(f'{월_1}일자 기사 크롤링합니다.')\n",
    "                print('-'*25)\n",
    "                for 월1 in range(len(면)):\n",
    "                    i면타이틀=[]\n",
    "                    타이틀제목=soup.select('div.newspaper_inner')[월1]\n",
    "                    타이틀제목s=타이틀제목.find_all('strong')\n",
    "                    for x1 in 타이틀제목s:\n",
    "                        i면타이틀.append(x1.text)\n",
    "                    하루타이틀.append(i면타이틀)\n",
    "\n",
    "                df1.loc[len(df1)]=['한국경제',하루타이틀,date]\n",
    "        \n",
    "        df1.to_csv('hankyong_202101.csv',encoding='cp949')\n",
    "    \n",
    "    elif i==2:\n",
    "        for 월_2 in range(1,29):\n",
    "            하루타이틀=[]\n",
    "            if 월_2 <10:\n",
    "                date='2021020{}'.format(월_2)\n",
    "                response=requests.get('https://media.naver.com/press/015/newspaper',headers=request_headers,\n",
    "                params={'date':date}\n",
    "                )\n",
    "            else:\n",
    "                date='202102{}'.format(월_2)\n",
    "                response=requests.get('https://media.naver.com/press/015/newspaper',headers=request_headers,\n",
    "                params={'date':date}\n",
    "                )\n",
    "            \n",
    "            soup=BeautifulSoup(response.text)\n",
    "            면=soup.select('div.newspaper_inner')\n",
    "    \n",
    "            if len(면)<1:\n",
    "                print(f'{월_2}일자는 기사가 없습니다 데헷')\n",
    "                print('-'*25)\n",
    "                continue\n",
    "            else:\n",
    "                print(f'{월_2}일자 기사 크롤링합니다.')\n",
    "                print('-'*25)\n",
    "                for 월2 in range(len(면)):\n",
    "                    i면타이틀=[]\n",
    "                    타이틀제목=soup.select('div.newspaper_inner')[월2]\n",
    "                    타이틀제목s=타이틀제목.find_all('strong')\n",
    "                    for x2 in 타이틀제목s:\n",
    "                        i면타이틀.append(x2.text)\n",
    "                    하루타이틀.append(i면타이틀)\n",
    "\n",
    "                df2.loc[len(df2)]=['한국경제',하루타이틀,date]\n",
    "\n",
    "        df2.to_csv('hankyong_202102.csv',encoding='cp949')\n",
    "               \n",
    "    elif i==3:\n",
    "        for 월_3 in range(1,32):\n",
    "            하루타이틀=[]\n",
    "            if 월_3 <10:\n",
    "                date='2021030{}'.format(월_3)\n",
    "                response=requests.get('https://media.naver.com/press/015/newspaper',headers=request_headers,\n",
    "                params={'date':date}\n",
    "                )\n",
    "            else:\n",
    "                date='202103{}'.format(월_3)\n",
    "                response=requests.get('https://media.naver.com/press/015/newspaper',headers=request_headers,\n",
    "                params={'date':date}\n",
    "                )\n",
    "            \n",
    "            soup=BeautifulSoup(response.text)\n",
    "            면=soup.select('div.newspaper_inner')\n",
    "    \n",
    "            if len(면)<1:\n",
    "                print(f'{월_3}일자는 기사가 없습니다 데헷')\n",
    "                print('-'*25)\n",
    "                continue\n",
    "            else:\n",
    "                print(f'{월_3}일자 기사 크롤링합니다.')\n",
    "                print('-'*25)\n",
    "                for 월3 in range(len(면)):\n",
    "                    i면타이틀=[]\n",
    "                    타이틀제목=soup.select('div.newspaper_inner')[월3]\n",
    "                    타이틀제목s=타이틀제목.find_all('strong')\n",
    "                    for x3 in 타이틀제목s:\n",
    "                        i면타이틀.append(x3.text)\n",
    "                    하루타이틀.append(i면타이틀)\n",
    "\n",
    "                df3.loc[len(df3)]=['한국경제',하루타이틀,date]\n",
    "\n",
    "        df3.to_csv('hankyong_202103.csv',encoding='cp949')\n",
    "    elif i==4:\n",
    "        for 월_4 in range(1,31):\n",
    "            하루타이틀=[]\n",
    "            if 월_4 <10:\n",
    "                date='2021040{}'.format(월_4)\n",
    "                response=requests.get('https://media.naver.com/press/015/newspaper',headers=request_headers,\n",
    "                params={'date':date}\n",
    "                )\n",
    "            else:\n",
    "                date='202104{}'.format(월_4)\n",
    "                response=requests.get('https://media.naver.com/press/015/newspaper',headers=request_headers,\n",
    "                params={'date':date}\n",
    "                )\n",
    "            \n",
    "            soup=BeautifulSoup(response.text)\n",
    "            면=soup.select('div.newspaper_inner')\n",
    "    \n",
    "            if len(면)<1:\n",
    "                print(f'{월_4}일자는 기사가 없습니다 데헷')\n",
    "                print('-'*25)\n",
    "                continue\n",
    "            else:\n",
    "                print(f'{월_4}일자 기사 크롤링합니다.')\n",
    "                print('-'*25)\n",
    "                for 월4 in range(len(면)):\n",
    "                    i면타이틀=[]\n",
    "                    타이틀제목=soup.select('div.newspaper_inner')[월4]\n",
    "                    타이틀제목s=타이틀제목.find_all('strong')\n",
    "                    for x2 in 타이틀제목s:\n",
    "                        i면타이틀.append(x2.text)\n",
    "                    하루타이틀.append(i면타이틀)\n",
    "\n",
    "                df4.loc[len(df4)]=['한국경제',하루타이틀,date]\n",
    "\n",
    "        df4.to_csv('hankyong_202104.csv',encoding='cp949')\n",
    "                \n",
    "    elif i==5:\n",
    "        for 월_5 in range(1,32):\n",
    "            하루타이틀=[]\n",
    "            if 월_5 <10:\n",
    "                date='2021050{}'.format(월_5)\n",
    "                response=requests.get('https://media.naver.com/press/015/newspaper',headers=request_headers,\n",
    "                params={'date':date}\n",
    "                )\n",
    "            else:\n",
    "                date='202105{}'.format(월_5)\n",
    "                response=requests.get('https://media.naver.com/press/015/newspaper',headers=request_headers,\n",
    "                params={'date':date}\n",
    "                )\n",
    "            \n",
    "            soup=BeautifulSoup(response.text)\n",
    "            면=soup.select('div.newspaper_inner')\n",
    "    \n",
    "            if len(면)<1:\n",
    "                print(f'{월_5}일자는 기사가 없습니다 데헷')\n",
    "                print('-'*25)\n",
    "                continue\n",
    "            else:\n",
    "                print(f'{월_5}일자 기사 크롤링합니다.')\n",
    "                print('-'*25)\n",
    "                for 월5 in range(len(면)):\n",
    "                    i면타이틀=[]\n",
    "                    타이틀제목=soup.select('div.newspaper_inner')[월5]\n",
    "                    타이틀제목s=타이틀제목.find_all('strong')\n",
    "                    for x5 in 타이틀제목s:\n",
    "                        i면타이틀.append(x5.text)\n",
    "                    하루타이틀.append(i면타이틀)\n",
    "\n",
    "                df5.loc[len(df5)]=['한국경제',하루타이틀,date]\n",
    "\n",
    "        df5.to_csv('hankyong_202105.csv',encoding='cp949')\n",
    "    elif i==6:\n",
    "        for 월_6 in range(1,31):\n",
    "            하루타이틀=[]\n",
    "            if 월_6 <10:\n",
    "                date='2021060{}'.format(월_6)\n",
    "                response=requests.get('https://media.naver.com/press/015/newspaper',headers=request_headers,\n",
    "                params={'date':date}\n",
    "                )\n",
    "            else:\n",
    "                date='202106{}'.format(월_6)\n",
    "                response=requests.get('https://media.naver.com/press/015/newspaper',headers=request_headers,\n",
    "                params={'date':date}\n",
    "                )\n",
    "            \n",
    "            soup=BeautifulSoup(response.text)\n",
    "            면=soup.select('div.newspaper_inner')\n",
    "    \n",
    "            if len(면)<1:\n",
    "                print(f'{월_6}일자는 기사가 없습니다 데헷')\n",
    "                print('-'*25)\n",
    "                continue\n",
    "            else:\n",
    "                print(f'{월_6}일자 기사 크롤링합니다.')\n",
    "                print('-'*25)\n",
    "                for 월6 in range(len(면)):\n",
    "                    i면타이틀=[]\n",
    "                    타이틀제목=soup.select('div.newspaper_inner')[월6]\n",
    "                    타이틀제목s=타이틀제목.find_all('strong')\n",
    "                    for x6 in 타이틀제목s:\n",
    "                        i면타이틀.append(x6.text)\n",
    "                    하루타이틀.append(i면타이틀)\n",
    "\n",
    "                df6.loc[len(df6)]=['한국경제',하루타이틀,date]\n",
    "\n",
    "        df6.to_csv('hankyong_202106.csv',encoding='cp949')\n",
    "        \n",
    "    elif i==7:\n",
    "        for 월_7 in range(1,32):\n",
    "            하루타이틀=[]\n",
    "            if 월_7 <10:\n",
    "                date='2021070{}'.format(월_7)\n",
    "                response=requests.get('https://media.naver.com/press/015/newspaper',headers=request_headers,\n",
    "                params={'date':date}\n",
    "                )\n",
    "            else:\n",
    "                date='202107{}'.format(월_7)\n",
    "                response=requests.get('https://media.naver.com/press/015/newspaper',headers=request_headers,\n",
    "                params={'date':date}\n",
    "                )\n",
    "            \n",
    "            soup=BeautifulSoup(response.text)\n",
    "            면=soup.select('div.newspaper_inner')\n",
    "    \n",
    "            if len(면)<1:\n",
    "                print(f'{월_7}일자는 기사가 없습니다 데헷')\n",
    "                print('-'*25)\n",
    "                continue\n",
    "            else:\n",
    "                print(f'{월_7}일자 기사 크롤링합니다.')\n",
    "                print('-'*25)\n",
    "                for 월7 in range(len(면)):\n",
    "                    i면타이틀=[]\n",
    "                    타이틀제목=soup.select('div.newspaper_inner')[월7]\n",
    "                    타이틀제목s=타이틀제목.find_all('strong')\n",
    "                    for x7 in 타이틀제목s:\n",
    "                        i면타이틀.append(x7.text)\n",
    "                    하루타이틀.append(i면타이틀)\n",
    "\n",
    "                df7.loc[len(df7)]=['한국경제',하루타이틀,date]\n",
    "\n",
    "        df7.to_csv('hankyong_202107.csv',encoding='cp949')\n",
    "        \n",
    "    elif i==8:\n",
    "        for 월_8 in range(1,32):\n",
    "            하루타이틀=[]\n",
    "            if 월_8 <10:\n",
    "                date='2021080{}'.format(월_8)\n",
    "                response=requests.get('https://media.naver.com/press/015/newspaper',\n",
    "                params={'date':date}\n",
    "                )\n",
    "            else:\n",
    "                date='202108{}'.format(월_8)\n",
    "                response=requests.get('https://media.naver.com/press/015/newspaper',\n",
    "                params={'date':date}\n",
    "                )\n",
    "            \n",
    "            soup=BeautifulSoup(response.text)\n",
    "            면=soup.select('div.newspaper_inner')\n",
    "    \n",
    "            if len(면)<1:\n",
    "                print(f'{월_8}일자는 기사가 없습니다 데헷')\n",
    "                print('-'*25)\n",
    "                continue\n",
    "            else:\n",
    "                print(f'{월_8}일자 기사 크롤링합니다.')\n",
    "                print('-'*25)\n",
    "                for 월8 in range(len(면)):\n",
    "                    i면타이틀=[]\n",
    "                    타이틀제목=soup.select('div.newspaper_inner')[월8]\n",
    "                    타이틀제목s=타이틀제목.find_all('strong')\n",
    "                    for x8 in 타이틀제목s:\n",
    "                        i면타이틀.append(x8.text)\n",
    "                    하루타이틀.append(i면타이틀)\n",
    "\n",
    "                df8.loc[len(df8)]=['한국경제',하루타이틀,date]\n",
    "\n",
    "        df8.to_csv('hankyong_202108.csv',encoding='cp949')\n",
    "        \n",
    "    elif i==9:\n",
    "        for 월_9 in range(1,31):\n",
    "            하루타이틀=[]\n",
    "            if 월_9 <10:\n",
    "                date='2021090{}'.format(월_9)\n",
    "                response=requests.get('https://media.naver.com/press/015/newspaper',\n",
    "                params={'date':date}\n",
    "                )\n",
    "            else:\n",
    "                date='202109{}'.format(월_9)\n",
    "                response=requests.get('https://media.naver.com/press/015/newspaper',\n",
    "                params={'date':date}\n",
    "                )\n",
    "            \n",
    "            soup=BeautifulSoup(response.text)\n",
    "            면=soup.select('div.newspaper_inner')\n",
    "    \n",
    "            if len(면)<1:\n",
    "                print(f'{월_9}일자는 기사가 없습니다 데헷')\n",
    "                print('-'*25)\n",
    "                continue\n",
    "            else:\n",
    "                print(f'{월_9}일자 기사 크롤링합니다.')\n",
    "                print('-'*25)\n",
    "                for 월9 in range(len(면)):\n",
    "                    i면타이틀=[]\n",
    "                    타이틀제목=soup.select('div.newspaper_inner')[월9]\n",
    "                    타이틀제목s=타이틀제목.find_all('strong')\n",
    "                    for x9 in 타이틀제목s:\n",
    "                        i면타이틀.append(x9.text)\n",
    "                    하루타이틀.append(i면타이틀)\n",
    "\n",
    "                df9.loc[len(df9)]=['한국경제',하루타이틀,date]\n",
    "\n",
    "        df9.to_csv('hankyong_202109.csv',encoding='cp949')\n",
    "        \n",
    "    elif i==10:\n",
    "        for 월_10 in range(1,32):\n",
    "            하루타이틀=[]\n",
    "            if 월_10 <10:\n",
    "                date='2021100{}'.format(월_10)\n",
    "                response=requests.get('https://media.naver.com/press/015/newspaper',\n",
    "                params={'date':date}\n",
    "                )\n",
    "            else:\n",
    "                date='202110{}'.format(월_10)\n",
    "                response=requests.get('https://media.naver.com/press/015/newspaper',\n",
    "                params={'date':date}\n",
    "                )\n",
    "            \n",
    "            soup=BeautifulSoup(response.text)\n",
    "            면=soup.select('div.newspaper_inner')\n",
    "    \n",
    "            if len(면)<1:\n",
    "                print(f'{월_10}일자는 기사가 없습니다 데헷')\n",
    "                print('-'*25)\n",
    "                continue\n",
    "            else:\n",
    "                print(f'{월_10}일자 기사 크롤링합니다.')\n",
    "                print('-'*25)\n",
    "                for 월10 in range(len(면)):\n",
    "                    i면타이틀=[]\n",
    "                    타이틀제목=soup.select('div.newspaper_inner')[월10]\n",
    "                    타이틀제목s=타이틀제목.find_all('strong')\n",
    "                    for x10 in 타이틀제목s:\n",
    "                        i면타이틀.append(x10.text)\n",
    "                    하루타이틀.append(i면타이틀)\n",
    "\n",
    "                df10.loc[len(df10)]=['한국경제',하루타이틀,date]\n",
    "\n",
    "        df10.to_csv('hankyong_202110.csv',encoding='cp949')\n",
    "        \n",
    "    elif i==11:\n",
    "        for 월_11 in range(1,31):\n",
    "            하루타이틀=[]\n",
    "            if 월_11 <10:\n",
    "                date='2021110{}'.format(월_11)\n",
    "                response=requests.get('https://media.naver.com/press/015/newspaper',\n",
    "                params={'date':date}\n",
    "                )\n",
    "            else:\n",
    "                date='202111{}'.format(월_11)\n",
    "                response=requests.get('https://media.naver.com/press/015/newspaper',\n",
    "                params={'date':date}\n",
    "                )\n",
    "            \n",
    "            soup=BeautifulSoup(response.text)\n",
    "            면=soup.select('div.newspaper_inner')\n",
    "    \n",
    "            if len(면)<1:\n",
    "                print(f'{월_11}일자는 기사가 없습니다 데헷')\n",
    "                print('-'*25)\n",
    "                continue\n",
    "            else:\n",
    "                print(f'{월_11}일자 기사 크롤링합니다.')\n",
    "                print('-'*25)\n",
    "                for 월11 in range(len(면)):\n",
    "                    i면타이틀=[]\n",
    "                    타이틀제목=soup.select('div.newspaper_inner')[월11]\n",
    "                    타이틀제목s=타이틀제목.find_all('strong')\n",
    "                    for x11 in 타이틀제목s:\n",
    "                        i면타이틀.append(x11.text)\n",
    "                    하루타이틀.append(i면타이틀)\n",
    "\n",
    "                df11.loc[len(df11)]=['한국경제',하루타이틀,date]\n",
    "\n",
    "        df11.to_csv('hankyong_202111.csv',encoding='cp949')\n",
    "        \n",
    "    elif i==12:\n",
    "        for 월_12 in range(1,29):\n",
    "            하루타이틀=[]\n",
    "            if 월_12 <10:\n",
    "                date='2021120{}'.format(월_12)\n",
    "                response=requests.get('https://media.naver.com/press/015/newspaper',\n",
    "                params={'date':date}\n",
    "                )\n",
    "            else:\n",
    "                date='202112{}'.format(월_12)\n",
    "                response=requests.get('https://media.naver.com/press/015/newspaper',\n",
    "                params={'date':date}\n",
    "                )\n",
    "            \n",
    "            soup=BeautifulSoup(response.text)\n",
    "            면=soup.select('div.newspaper_inner')\n",
    "    \n",
    "            if len(면)<1:\n",
    "                print(f'{월_12}일자는 기사가 없습니다 데헷')\n",
    "                print('-'*25)\n",
    "                continue\n",
    "            else:\n",
    "                print(f'{월_12}일자 기사 크롤링합니다.')\n",
    "                print('-'*25)\n",
    "                for 월12 in range(len(면)):\n",
    "                    i면타이틀=[]\n",
    "                    타이틀제목=soup.select('div.newspaper_inner')[월12]\n",
    "                    타이틀제목s=타이틀제목.find_all('strong')\n",
    "                    for x12 in 타이틀제목s:\n",
    "                        i면타이틀.append(x12.text)\n",
    "                    하루타이틀.append(i면타이틀)\n",
    "\n",
    "                df12.loc[len(df12)]=['한국경제',하루타이틀,date]\n",
    "\n",
    "        df12.to_csv('hankyong_202112.csv',encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282aa395",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8de5c82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
