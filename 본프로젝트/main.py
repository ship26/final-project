from transformers import PreTrainedTokenizerFast
tokenizer = PreTrainedTokenizerFast.from_pretrained("skt/kogpt2-base-v2",
bos_token='</s>', eos_token='</s>', unk_token='<unk>',
pad_token='<pad>', mask_token='<mask>') 
tokenizer.tokenize("ì•ˆë…•í•˜ì„¸ìš”. í•œêµ­ì–´ GPT-2 ìž…ë‹ˆë‹¤.ðŸ˜¤:)l^o")